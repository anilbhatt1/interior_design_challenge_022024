{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b68615a1-f14c-4e2d-9189-f57969a31719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar  9 11:18:07 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.161.07             Driver Version: 535.161.07   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA RTX A4000               On  | 00000000:08:00.0 Off |                  Off |\n",
      "| 41%   26C    P8              13W / 100W |     11MiB / 16376MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fc972b6-179c-4d04-ba30-53bf65302a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Union, List\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from transformers import CLIPTextModel, CLIPTokenizer, DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86e3b862-4d39-49eb-be9e-d3b410d98095",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_encoder = CLIPTextModel.from_pretrained(\n",
    "    \"int_ch/models/runwayml--stable-diffusion-inpainting\",\n",
    "    subfolder=\"text_encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a862d080-e47e-4df0-81f3-2fde816eaca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moved to cuda\n"
     ]
    }
   ],
   "source": [
    "text_encoder.to('cuda', dtype=torch.float32)\n",
    "print('moved to cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "420a2f7a-05e4-4547-9332-985270801e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CLIPTokenizer.from_pretrained(\n",
    "    \"int_ch/models/runwayml--stable-diffusion-inpainting\",\n",
    "    subfolder=\"tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "769398e8-5500-47f4-a986-f217f8cd1fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(caption):\n",
    "    return tokenizer(caption, truncation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "189a8f34-248a-4753-85d8-ab0d2a5cecf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a48405e5-099b-4798-97bc-109685022fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption1 = \"Photorealistic interior design of a mid-century modern living room with a focus on warm wood tones and pops of color. \\\n",
    "The room features a large plush velvet sectional sofa in a rich emerald green, paired with a mid-century modern wood \\\n",
    "and glass coffee table.Ample natural light streams \\\n",
    "    through large windows with white sheer curtains. A statement art piece with abstract expressionist elements hangs above \\\n",
    "    a mid-century modern credenza.\"\n",
    "\n",
    "caption2 = \"A Moroccan-style rug with geometric patterns adds texture to the floor. Ample natural light streams \\\n",
    "    through large windows with white sheer curtains. A statement art piece with abstract expressionist elements hangs above \\\n",
    "    a mid-century modern credenza. Lush Fiddle Leaf Fig and Monstera Deliciosa plants add a touch of nature to the space.\\\n",
    "    The room features a large plush velvet sectional sofa in a rich emerald green, paired with a mid-century modern wood \\\n",
    "and glass coffee table.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fa1990e2-6dc4-4fd3-b213-60c541fa0fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_lst = [caption1, caption2]\n",
    "prompt_token_lst = []\n",
    "for prompt in prompt_lst:\n",
    "    prompt_dict = tokenize_function(prompt)\n",
    "    prompt_token_lst.append(prompt_dict)\n",
    "prompt_tensors = data_collator(prompt_token_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8b57f151-1e64-40e9-a04c-bd337ee5bf58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 95])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_tensors['input_ids'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1f43b5d5-1731-4c22-86c5-b0ee3d3ee97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[49406,  1153, 16157,  7305,  1681,   539,   320,  4734,   268,  4275,\n",
       "          4077,  2815,  1530,   593,   320,  4353,   525,  3616,  1704, 14744,\n",
       "           537, 11705,   539,  3140,   269,   518,  1530,  4643,   320,  3638,\n",
       "         18926, 11063, 21876, 15723,   530,   320,  4021, 16980,  1901,   267,\n",
       "         12433,   593,   320,  4734,   268,  4275,  4077,  1704,   537,  3313,\n",
       "          2453,  2175,   269, 49407]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collated_captions['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5a5cb1b5-2363-4641-a37f-b815080b04ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = prompt_tensors['input_ids'].to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4877f944-92e9-4c03-996f-fe124dd7fce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.modeling_outputs.BaseModelOutputWithPooling"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = text_encoder(cc)\n",
    "type(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "da6eafbd-dfaa-4cd1-b9f9-c16ea7c23984",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():  # Disable gradient calculation for efficiency\n",
    "  text_embeddings = text_encoder(cc).pooler_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "11e99115-2393-45dc-a33a-5ae1adc1cba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 768])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97c0074b-426a-4e9d-9938-5b14fd804989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_encode(inputs, text_encoder, device, max_seq_len=75):\n",
    "    embeddings = []\n",
    "    tokens = inputs['input_ids']\n",
    "    attention_mask = inputs['attention_mask']\n",
    "    num_chunks = (tokens.size(1) + max_seq_len - 1) // max_seq_len\n",
    "\n",
    "    text_encoder = text_encoder.to(device)\n",
    "    tokens = tokens.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "    \n",
    "    for i in range(num_chunks):\n",
    "        start_idx = i * max_seq_len\n",
    "        end_idx = start_idx + max_seq_len\n",
    "        chunk_tokens = tokens[:, start_idx:end_idx]\n",
    "        # chunk_attention_mask = attention_mask[:, start_idx:end_idx]\n",
    "\n",
    "        chunk_embeddings = text_encoder.text_model.embeddings.token_embedding(chunk_tokens)\n",
    "\n",
    "        chunk_size = chunk_tokens.size(1)\n",
    "        position_ids = torch.arange(start_idx, start_idx + chunk_size, dtype=torch.long)\n",
    "        position_ids = position_ids.unsqueeze(0).expand(chunk_tokens.size(0), chunk_size)\n",
    "\n",
    "        position_ids = torch.clamp(position_ids.to(device), max=text_encoder.text_model.embeddings.position_embedding.num_embeddings - 1)\n",
    "        position_embeddings = text_encoder.text_model.embeddings.position_embedding(position_ids)\n",
    "        chunk_embeddings += position_embeddings\n",
    "\n",
    "        embeddings.append(chunk_embeddings)\n",
    "\n",
    "    concatenated_embeddings = torch.cat(embeddings, dim=1)\n",
    "    attention_mask_expanded = attention_mask.unsqueeze(1).unsqueeze(2).repeat(1, 1, attention_mask.shape[1], 1)\n",
    "    encoder_outputs = text_encoder.text_model.encoder(concatenated_embeddings, attention_mask=attention_mask_expanded)\n",
    "    return(encoder_outputs.last_hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b59ae77-3f4c-451c-9366-ac291129f100",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_hidden_states = do_encode(collated_captions, text_encoder, 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f90cf0e-0c3c-4783-a1a9-045e9b81b589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 119, 768])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_hidden_states.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c9860224-2650-4161-96cf-c6bde33590e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "696bd0ee-b053-4fea-9e9f-123540c09f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87bbc56-589e-46f2-bb4b-70dc3d0c6dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/opt/conda/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_5m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_5m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/opt/conda/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_11m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_11m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/opt/conda/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/opt/conda/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_384 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/opt/conda/lib/python3.10/site-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_512 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_512. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/opt/conda/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "The config attributes {'dropout': 0.0, 'sample_size': 32} were passed to ControlNetModel, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "Loading pipeline components...: 100%|█████████████| 6/6 [00:02<00:00,  2.01it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.controlnet.pipeline_controlnet_inpaint.StableDiffusionControlNetInpaintPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]A Bauhaus-inspired living room with a sleek black leather sofa, a tubular steel coffee table exemplifying modernist design, and a geometric patterned rug adding a touch of artistic flair.\n",
      "(1344, 896) (768, 512)\n",
      "\n",
      "  0%|                                                    | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 1/50 [00:00<00:29,  1.66it/s]\u001b[A\n",
      "  4%|█▊                                          | 2/50 [00:01<00:27,  1.72it/s]\u001b[A\n",
      "  6%|██▋                                         | 3/50 [00:01<00:26,  1.75it/s]\u001b[A\n",
      "  8%|███▌                                        | 4/50 [00:02<00:25,  1.78it/s]\u001b[A\n",
      " 10%|████▍                                       | 5/50 [00:02<00:25,  1.79it/s]\u001b[A\n",
      " 12%|█████▎                                      | 6/50 [00:03<00:24,  1.80it/s]\u001b[A\n",
      " 14%|██████▏                                     | 7/50 [00:03<00:23,  1.81it/s]\u001b[A\n",
      " 16%|███████                                     | 8/50 [00:04<00:23,  1.81it/s]\u001b[A\n",
      " 18%|███████▉                                    | 9/50 [00:05<00:22,  1.82it/s]\u001b[A\n",
      " 20%|████████▌                                  | 10/50 [00:05<00:21,  1.83it/s]\u001b[A\n",
      " 22%|█████████▍                                 | 11/50 [00:06<00:21,  1.83it/s]\u001b[A\n",
      " 24%|██████████▎                                | 12/50 [00:06<00:20,  1.83it/s]\u001b[A\n",
      " 26%|███████████▏                               | 13/50 [00:07<00:20,  1.83it/s]\u001b[A\n",
      " 28%|████████████                               | 14/50 [00:07<00:19,  1.84it/s]\u001b[A\n",
      " 30%|████████████▉                              | 15/50 [00:08<00:19,  1.84it/s]\u001b[A\n",
      " 32%|█████████████▊                             | 16/50 [00:08<00:18,  1.84it/s]\u001b[A\n",
      " 34%|██████████████▌                            | 17/50 [00:09<00:17,  1.83it/s]\u001b[A\n",
      " 36%|███████████████▍                           | 18/50 [00:09<00:17,  1.84it/s]\u001b[A\n",
      " 38%|████████████████▎                          | 19/50 [00:10<00:16,  1.83it/s]\u001b[A\n",
      " 40%|█████████████████▏                         | 20/50 [00:11<00:16,  1.83it/s]\u001b[A\n",
      " 42%|██████████████████                         | 21/50 [00:11<00:15,  1.83it/s]\u001b[A\n",
      " 44%|██████████████████▉                        | 22/50 [00:12<00:15,  1.83it/s]\u001b[A\n",
      " 46%|███████████████████▊                       | 23/50 [00:12<00:14,  1.83it/s]\u001b[A\n",
      " 48%|████████████████████▋                      | 24/50 [00:13<00:14,  1.83it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 25/50 [00:13<00:13,  1.83it/s]\u001b[A\n",
      " 52%|██████████████████████▎                    | 26/50 [00:14<00:13,  1.83it/s]\u001b[A\n",
      " 54%|███████████████████████▏                   | 27/50 [00:14<00:12,  1.83it/s]\u001b[A\n",
      " 56%|████████████████████████                   | 28/50 [00:15<00:12,  1.83it/s]\u001b[A\n",
      " 58%|████████████████████████▉                  | 29/50 [00:15<00:11,  1.83it/s]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 30/50 [00:16<00:10,  1.83it/s]\u001b[A\n",
      " 62%|██████████████████████████▋                | 31/50 [00:17<00:10,  1.82it/s]\u001b[A\n",
      " 64%|███████████████████████████▌               | 32/50 [00:17<00:09,  1.82it/s]\u001b[A\n",
      " 66%|████████████████████████████▍              | 33/50 [00:18<00:09,  1.82it/s]\u001b[A\n",
      " 68%|█████████████████████████████▏             | 34/50 [00:18<00:08,  1.82it/s]\u001b[A\n",
      " 70%|██████████████████████████████             | 35/50 [00:19<00:08,  1.82it/s]\u001b[A\n",
      " 72%|██████████████████████████████▉            | 36/50 [00:19<00:07,  1.82it/s]\u001b[A\n",
      " 74%|███████████████████████████████▊           | 37/50 [00:20<00:07,  1.82it/s]\u001b[A\n",
      " 76%|████████████████████████████████▋          | 38/50 [00:20<00:06,  1.82it/s]\u001b[A\n",
      " 78%|█████████████████████████████████▌         | 39/50 [00:21<00:06,  1.82it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 40/50 [00:21<00:05,  1.82it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 41/50 [00:22<00:04,  1.81it/s]\u001b[A\n",
      " 84%|████████████████████████████████████       | 42/50 [00:23<00:04,  1.82it/s]\u001b[A\n",
      " 86%|████████████████████████████████████▉      | 43/50 [00:23<00:03,  1.81it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▊     | 44/50 [00:24<00:03,  1.82it/s]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 45/50 [00:24<00:02,  1.81it/s]\u001b[A\n",
      " 92%|███████████████████████████████████████▌   | 46/50 [00:25<00:02,  1.81it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▍  | 47/50 [00:25<00:01,  1.81it/s]\u001b[A\n",
      " 96%|█████████████████████████████████████████▎ | 48/50 [00:26<00:01,  1.81it/s]\u001b[A\n",
      " 98%|██████████████████████████████████████████▏| 49/50 [00:26<00:00,  1.81it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 50/50 [00:27<00:00,  1.82it/s]\u001b[A\n",
      " 33%|███████████████                              | 1/3 [00:45<01:31, 45.52s/it]A glamorous master bedroom in Hollywood Regency style, boasting a plush tufted headboard, mirrored furniture reflecting elegance, luxurious fabrics in rich textures, and opulent gold accents for a touch of luxury.\n",
      "(1344, 896) (768, 512)\n",
      "\n",
      "  0%|                                                    | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▉                                           | 1/50 [00:00<00:28,  1.70it/s]\u001b[A\n",
      "  4%|█▊                                          | 2/50 [00:01<00:27,  1.75it/s]\u001b[A\n",
      "  6%|██▋                                         | 3/50 [00:01<00:26,  1.80it/s]\u001b[A\n",
      "  8%|███▌                                        | 4/50 [00:02<00:25,  1.79it/s]\u001b[A\n",
      " 10%|████▍                                       | 5/50 [00:02<00:24,  1.81it/s]\u001b[A\n",
      " 12%|█████▎                                      | 6/50 [00:03<00:24,  1.81it/s]\u001b[A\n",
      " 14%|██████▏                                     | 7/50 [00:03<00:23,  1.82it/s]\u001b[A\n",
      " 16%|███████                                     | 8/50 [00:04<00:23,  1.81it/s]\u001b[A\n",
      " 18%|███████▉                                    | 9/50 [00:04<00:22,  1.82it/s]\u001b[A\n",
      " 20%|████████▌                                  | 10/50 [00:05<00:22,  1.81it/s]\u001b[A\n",
      " 22%|█████████▍                                 | 11/50 [00:06<00:21,  1.81it/s]\u001b[A\n",
      " 24%|██████████▎                                | 12/50 [00:06<00:20,  1.81it/s]\u001b[A\n",
      " 26%|███████████▏                               | 13/50 [00:07<00:20,  1.81it/s]\u001b[A\n",
      " 28%|████████████                               | 14/50 [00:07<00:19,  1.81it/s]\u001b[A\n",
      " 30%|████████████▉                              | 15/50 [00:08<00:19,  1.81it/s]\u001b[A\n",
      " 32%|█████████████▊                             | 16/50 [00:08<00:18,  1.81it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "! python 'int_ch/local_evaluation.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "418bfccc-f744-4e1e-ae14-2d4ecd41d231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIPTextModel(\n",
       "  (text_model): CLIPTextTransformer(\n",
       "    (embeddings): CLIPTextEmbeddings(\n",
       "      (token_embedding): Embedding(49408, 768)\n",
       "      (position_embedding): Embedding(77, 768)\n",
       "    )\n",
       "    (encoder): CLIPEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d6ada39b-0ba1-4a9d-92dd-c7c6760a79aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIPEncoder(\n",
       "  (layers): ModuleList(\n",
       "    (0-11): 12 x CLIPEncoderLayer(\n",
       "      (self_attn): CLIPAttention(\n",
       "        (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): CLIPMLP(\n",
       "        (activation_fn): QuickGELUActivation()\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      )\n",
       "      (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_encoder.text_model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "91061cc5-4949-484a-a0d5-ef83b28b697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pipeline_embeds(prompt, negative_prompt, device):\n",
    "    \"\"\" Get pipeline embeds for prompts bigger than the maxlength of the pipe\n",
    "    :param pipeline:\n",
    "    :param prompt:\n",
    "    :param negative_prompt:\n",
    "    :param device:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    max_length = tokenizer.model_max_length\n",
    "\n",
    "    # simple way to determine length of tokens\n",
    "    count_prompt = len(prompt.split(\" \"))\n",
    "    count_negative_prompt = len(negative_prompt.split(\" \"))\n",
    "\n",
    "    # create the tensor based on which prompt is longer\n",
    "    if count_prompt >= count_negative_prompt:\n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\", truncation=False).input_ids.to(device)\n",
    "        shape_max_length = input_ids.shape[-1]\n",
    "        negative_ids = tokenizer(negative_prompt, truncation=False, padding=\"max_length\",\n",
    "                                          max_length=shape_max_length, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "    else:\n",
    "        negative_ids = tokenizer(negative_prompt, return_tensors=\"pt\", truncation=False).input_ids.to(device)\n",
    "        shape_max_length = negative_ids.shape[-1]\n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\", truncation=False, padding=\"max_length\",\n",
    "                                       max_length=shape_max_length).input_ids.to(device)\n",
    "\n",
    "    print(f'shape_max_length : {shape_max_length} & max_length : {max_length}')\n",
    "    concat_embeds = []\n",
    "    neg_embeds = []\n",
    "    for i in range(0, shape_max_length, max_length):\n",
    "        concat_embeds.append(text_encoder(input_ids[:, i: i + max_length])[0])\n",
    "        neg_embeds.append(text_encoder(negative_ids[:, i: i + max_length])[0])\n",
    "\n",
    "    return torch.cat(concat_embeds, dim=1), torch.cat(neg_embeds, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b5d3266a-ef22-4e82-aeb0-34c425820cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape_max_length : 95 & max_length : 77\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 95, 768]), torch.Size([1, 95, 768]))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_e, n_e = get_pipeline_embeds(caption1, caption2, 'cuda')\n",
    "p_e.size(), n_e.size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
